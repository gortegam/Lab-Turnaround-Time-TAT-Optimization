{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103d6261",
   "metadata": {},
   "source": [
    "# Lab TAT — Simulation & What‑If Modeling (03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aae6fb",
   "metadata": {},
   "source": [
    "\n",
    "This notebook adds **prescriptive** analysis via discrete‑event simulation to answer questions like:\n",
    "- If we add 1 technologist on the Evening shift, how much does median TAT improve?\n",
    "- What SLA threshold achieves 95% compliance under current staffing?\n",
    "- How sensitive are outcomes to pre‑analytical delays?\n",
    "\n",
    "We simulate **analytical stage queues** (multi‑server) and fold in **pre** and **post** times to estimate total TAT and SLA hit rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad80d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "DAYS = 14\n",
    "HOURS = 24 * DAYS\n",
    "SLA_MIN = 240\n",
    "STAT_SHARE = 0.2\n",
    "PRE_MEAN_ROUTINE = 30\n",
    "PRE_MEAN_STAT = 15\n",
    "POST_MEAN = 20\n",
    "ANALYTICAL_MEAN = 60\n",
    "\n",
    "arrivals_per_hour_day = np.array([\n",
    "    10, 8, 6, 5, 5, 6, 8, 10, 12, 14, 16, 18,\n",
    "    18, 18, 18, 20, 22, 24, 26, 24, 20, 16, 12, 10\n",
    "], dtype=float)\n",
    "\n",
    "techs_per_hour_day = np.array([\n",
    "    2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 4,\n",
    "    4, 4, 4, 4, 5, 5, 5, 4, 3, 3, 2, 2\n",
    "], dtype=int)\n",
    "\n",
    "def repeat_profile(profile, days=DAYS):\n",
    "    return np.tile(profile, days)\n",
    "\n",
    "ARRIVALS_PER_HOUR = repeat_profile(arrivals_per_hour_day, DAYS)\n",
    "TECHS_PER_HOUR = repeat_profile(techs_per_hour_day, DAYS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def poisson_process_counts(lam, rng):\n",
    "    return rng.poisson(lam)\n",
    "\n",
    "def generate_arrival_times(counts, rng):\n",
    "    arrival_times = []\n",
    "    for h, c in enumerate(counts):\n",
    "        if c <= 0:\n",
    "            continue\n",
    "        minutes = rng.uniform(0, 60, size=c) + h*60\n",
    "        arrival_times.extend(minutes.tolist())\n",
    "    arrival_times = np.array(sorted(arrival_times))\n",
    "    return arrival_times\n",
    "\n",
    "def sample_pre_times(n, rng):\n",
    "    routine_n = int(np.round(n*(1-STAT_SHARE)))\n",
    "    stat_n = n - routine_n\n",
    "    pre_r = rng.gamma(shape=2.0, scale=PRE_MEAN_ROUTINE/2.0, size=routine_n)\n",
    "    pre_s = rng.gamma(shape=2.0, scale=PRE_MEAN_STAT/2.0, size=stat_n)\n",
    "    pre = np.concatenate([pre_r, pre_s])\n",
    "    rng.shuffle(pre)\n",
    "    return pre\n",
    "\n",
    "def sample_post_times(n, rng):\n",
    "    return rng.gamma(shape=2.0, scale=POST_MEAN/2.0, size=n)\n",
    "\n",
    "def sample_analytical_service(n, rng):\n",
    "    return rng.gamma(shape=2.0, scale=ANALYTICAL_MEAN/2.0, size=n)\n",
    "\n",
    "def server_counts_over_time(techs_profile):\n",
    "    return np.repeat(techs_profile, 60)\n",
    "\n",
    "def simulate_queue(arrival_times_min, service_times_min, servers_per_min):\n",
    "    n = len(arrival_times_min)\n",
    "    waiting = np.zeros(n)\n",
    "    start_times = np.zeros(n)\n",
    "    end_times = np.zeros(n)\n",
    "\n",
    "    current_minute = 0\n",
    "    active_servers = int(servers_per_min[0])\n",
    "    next_free = np.zeros(active_servers)\n",
    "\n",
    "    for i, t in enumerate(arrival_times_min):\n",
    "        minute = int(np.floor(t))\n",
    "\n",
    "        if minute != current_minute:\n",
    "            current_minute = minute\n",
    "            target_servers = int(servers_per_min[current_minute])\n",
    "            current_servers = len(next_free)\n",
    "            if target_servers > current_servers:\n",
    "                next_free = np.concatenate([next_free, np.full(target_servers-current_servers, current_minute)])\n",
    "            elif target_servers < current_servers:\n",
    "                keep_idx = np.argsort(next_free)[:target_servers]\n",
    "                next_free = next_free[keep_idx]\n",
    "\n",
    "        s_idx = np.argmin(next_free)\n",
    "        start = max(t, next_free[s_idx])\n",
    "        wait = max(0.0, start - t)\n",
    "        end = start + service_times_min[i]\n",
    "\n",
    "        waiting[i] = wait\n",
    "        start_times[i] = start\n",
    "        end_times[i] = end\n",
    "        next_free[s_idx] = end\n",
    "\n",
    "    return waiting, start_times, end_times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fa2096",
   "metadata": {},
   "source": [
    "## Run Baseline Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d33c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hourly_counts = poisson_process_counts(ARRIVALS_PER_HOUR, rng)\n",
    "arrivals_min = generate_arrival_times(hourly_counts, rng)\n",
    "n = len(arrivals_min)\n",
    "\n",
    "pre = sample_pre_times(n, rng)\n",
    "post = sample_post_times(n, rng)\n",
    "service = sample_analytical_service(n, rng)\n",
    "\n",
    "servers_per_min = server_counts_over_time(TECHS_PER_HOUR)\n",
    "wait, start_svc, end_svc = simulate_queue(arrivals_min, service, servers_per_min)\n",
    "\n",
    "tat_total = pre + wait + service + post\n",
    "\n",
    "median_tat = np.median(tat_total)\n",
    "p95_tat = np.percentile(tat_total, 95)\n",
    "sla_rate = np.mean(tat_total <= SLA_MIN) * 100\n",
    "\n",
    "baseline = {\n",
    "    \"orders\": int(n),\n",
    "    \"median_tat_min\": float(median_tat),\n",
    "    \"p95_tat_min\": float(p95_tat),\n",
    "    \"sla_rate_pct\": float(sla_rate),\n",
    "}\n",
    "baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Total TAT distribution\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.hist(tat_total, bins=40)\n",
    "ax.set_xlabel(\"Total TAT (minutes)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Baseline: Total TAT Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Daily SLA trend (group by day index)\n",
    "day_index = (arrivals_min // (60*24)).astype(int)\n",
    "sla_by_day = pd.Series(tat_total <= SLA_MIN).groupby(day_index).mean()*100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.plot(sla_by_day.index, sla_by_day.values, marker=\"o\")\n",
    "ax.set_xlabel(\"Day index\")\n",
    "ax.set_ylabel(\"SLA Hit Rate (%)\")\n",
    "ax.set_title(\"Baseline: Daily SLA Compliance\")\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71fc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_scenario(techs_per_hour_delta=None, sla_min=None, pre_mean_routine=None, pre_mean_stat=None):\n",
    "    global PRE_MEAN_ROUTINE, PRE_MEAN_STAT, SLA_MIN\n",
    "\n",
    "    _pre_r, _pre_s, _sla = PRE_MEAN_ROUTINE, PRE_MEAN_STAT, SLA_MIN\n",
    "\n",
    "    if sla_min is not None:\n",
    "        SLA_MIN = sla_min\n",
    "    if pre_mean_routine is not None:\n",
    "        PRE_MEAN_ROUTINE = pre_mean_routine\n",
    "    if pre_mean_stat is not None:\n",
    "        PRE_MEAN_STAT = pre_mean_stat\n",
    "\n",
    "    techs = TECHS_PER_HOUR.copy()\n",
    "    if techs_per_hour_delta is not None:\n",
    "        techs = techs + techs_per_hour_delta\n",
    "        techs = np.clip(techs, 1, None).astype(int)\n",
    "\n",
    "    counts = poisson_process_counts(ARRIVALS_PER_HOUR, rng)\n",
    "    arr = generate_arrival_times(counts, rng)\n",
    "    m = len(arr)\n",
    "    pre = sample_pre_times(m, rng)\n",
    "    post = sample_post_times(m, rng)\n",
    "    svc = sample_analytical_service(m, rng)\n",
    "    servers_min = server_counts_over_time(techs)\n",
    "\n",
    "    wait, s, e = simulate_queue(arr, svc, servers_min)\n",
    "    tat = pre + wait + svc + post\n",
    "\n",
    "    result = {\n",
    "        \"orders\": int(m),\n",
    "        \"median_tat_min\": float(np.median(tat)),\n",
    "        \"p95_tat_min\": float(np.percentile(tat,95)),\n",
    "        \"sla_rate_pct\": float(np.mean(tat <= SLA_MIN)*100),\n",
    "    }\n",
    "\n",
    "    PRE_MEAN_ROUTINE, PRE_MEAN_STAT, SLA_MIN = _pre_r, _pre_s, _sla\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ef276",
   "metadata": {},
   "source": [
    "## Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# +1 Evening Tech (16:00–20:00)\n",
    "delta_evening = np.zeros_like(TECHS_PER_HOUR)\n",
    "for d in range(DAYS):\n",
    "    base = d*24\n",
    "    for h in range(16, 21):\n",
    "        delta_evening[base+h] = 1\n",
    "\n",
    "sc1 = run_scenario(techs_per_hour_delta=delta_evening)\n",
    "\n",
    "# Redistribute: -1 Night (0–5) → +1 Evening (17–22)\n",
    "delta_redist = np.zeros_like(TECHS_PER_HOUR)\n",
    "for d in range(DAYS):\n",
    "    base = d*24\n",
    "    for h in range(0, 6):\n",
    "        delta_redist[base+h] = -1\n",
    "    for h in range(17, 23):\n",
    "        delta_redist[base+h] += 1\n",
    "\n",
    "sc2 = run_scenario(techs_per_hour_delta=delta_redist)\n",
    "\n",
    "# Pre-analytical improvement -20%\n",
    "sc3 = run_scenario(pre_mean_routine=PRE_MEAN_ROUTINE*0.8, pre_mean_stat=PRE_MEAN_STAT*0.8)\n",
    "\n",
    "# SLA sensitivity\n",
    "sla_grid = [120, 180, 240, 300, 360]\n",
    "sla_results = [run_scenario(sla_min=s) for s in sla_grid]\n",
    "\n",
    "summary = pd.DataFrame.from_records(\n",
    "    [dict(scenario=\"Baseline\", **baseline),\n",
    "     dict(scenario=\"+1 Evening Tech\", **sc1),\n",
    "     dict(scenario=\"Redistribute Night→Evening\", **sc2),\n",
    "     dict(scenario=\"Pre Delay -20%\", **sc3)]\n",
    ")\n",
    "sla_df = pd.DataFrame({\"SLA_min\": sla_grid, \"SLA_rate_pct\": [r[\"sla_rate_pct\"] for r in sla_results]})\n",
    "\n",
    "summary, sla_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56a0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scenario vs median TAT\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.bar(summary[\"scenario\"], summary[\"median_tat_min\"])\n",
    "ax.set_ylabel(\"Median Total TAT (min)\")\n",
    "ax.set_title(\"Scenario Comparison — Median TAT\")\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# SLA threshold vs compliance\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.plot(sla_df[\"SLA_min\"], sla_df[\"SLA_rate_pct\"], marker=\"o\")\n",
    "ax.set_xlabel(\"SLA Threshold (minutes)\")\n",
    "ax.set_ylabel(\"SLA Hit Rate (%)\")\n",
    "ax.set_title(\"SLA Sensitivity Curve\")\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8cd929",
   "metadata": {},
   "source": [
    "\n",
    "## Interpreting Results (fill with your numbers)\n",
    "- **+1 Evening Tech**: median TAT decreased by ~X minutes; SLA ↑ Y pp.  \n",
    "- **Redistribute Night→Evening**: similar improvement without adding headcount.  \n",
    "- **Pre‑analytical -20%**: Z pp improvement in SLA; suggests courier/triage optimizations can rival staffing changes.  \n",
    "- **SLA sensitivity**: To hit 95% compliance, you need ~W minutes SLA or staffing uplift of ...\n",
    "\n",
    "Summarize before/after metrics in your README.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
